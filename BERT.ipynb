{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Download and Import Repository"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d171592340e28a7c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in e:\\python\\textmining\\bert\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\python\\textmining\\bert\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\python\\textmining\\bert\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\python\\textmining\\bert\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python\\textmining\\bert\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python\\textmining\\bert\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python\\textmining\\bert\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python\\textmining\\bert\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in e:\\python\\textmining\\bert\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\python\\textmining\\bert\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\python\\textmining\\bert\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\python\\textmining\\bert\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\python\\textmining\\bert\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'relation'],\n",
      "        num_rows: 8000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'relation'],\n",
      "        num_rows: 2717\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T11:48:33.274201200Z",
     "start_time": "2025-02-22T11:48:29.249238700Z"
    }
   },
   "id": "3527dae28bc4ec15"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T11:48:39.330823800Z",
     "start_time": "2025-02-22T11:48:39.327771400Z"
    }
   },
   "id": "a5ec58b468e192cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the SemEval-2010 Task 8 dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52200f43d9afac99"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sentence', 'relation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"SemEvalWorkshop/sem_eval_2010_task_8\")\n",
    "\n",
    "# 转换成 Pandas DataFrame\n",
    "df_train = dataset['train'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()\n",
    "\n",
    "print(df_train.head())  # 确保数据加载正确\n",
    "print(df_train.columns)  # 查看列名"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T13:46:37.337499200Z",
     "start_time": "2025-02-22T13:46:34.278302Z"
    }
   },
   "id": "9464017764b5b78e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据预处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5a15970941c8551"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (1) 处理关系标签"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7fa86b509aa0d0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"Cause-Effect\", \"Instrument-Agency\", \"Product-Producer\",\n",
    "    \"Content-Container\", \"Entity-Origin\", \"Entity-Destination\",\n",
    "    \"Component-Whole\", \"Member-Collection\", \"Message-Topic\", \"Other\"\n",
    "]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T12:12:04.947188600Z",
     "start_time": "2025-02-22T12:12:04.944156400Z"
    }
   },
   "id": "62a921c28a5125cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (2) 处理句子"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede2fb0edc468b66"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "    sentence = sentence.replace(\"<e1>\", \"[E1]\").replace(\"</e1>\", \"[/E1]\")\n",
    "    sentence = sentence.replace(\"<e2>\", \"[E2]\").replace(\"</e2>\", \"[/E2]\")\n",
    "    return sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T12:12:09.845817800Z",
     "start_time": "2025-02-22T12:12:09.837800800Z"
    }
   },
   "id": "aedaca9d1ccda4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (3) 生成数据集格式"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3750cc1b3825b939"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class REDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 计算实体 <e1> 和 <e2> 在原始文本中的索引\n",
    "        e1_start = text.find(\"[E1]\")\n",
    "        e1_end = text.find(\"[/E1]\") + 4  # 包含 \"[/E1]\"\n",
    "        e2_start = text.find(\"[E2]\")\n",
    "        e2_end = text.find(\"[/E2]\") + 4  # 包含 \"[/E2]\"\n",
    "\n",
    "        # 移除标记，使得输入 BERT 的文本不会包含 \"[E1]\" 和 \"[E2]\"\n",
    "        clean_text = text.replace(\"[E1]\", \"\").replace(\"[/E1]\", \"\").replace(\"[E2]\", \"\").replace(\"[/E2]\", \"\")\n",
    "\n",
    "        # Tokenizer 编码\n",
    "        encoding = self.tokenizer(\n",
    "            clean_text, padding=\"max_length\", truncation=True,\n",
    "            max_length=self.max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        item[\"e1_pos\"] = torch.tensor([e1_start, e1_end], dtype=torch.long)\n",
    "        item[\"e2_pos\"] = torch.tensor([e2_start, e2_end], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "# 预处理数据\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_texts = [preprocess_text(sent) for sent in df_train[\"sentence\"]]\n",
    "test_texts = [preprocess_text(sent) for sent in df_test[\"sentence\"]]\n",
    "\n",
    "# 确保标签是数字\n",
    "if df_train[\"relation\"].dtype in [int, np.int32, np.int64]:\n",
    "    train_labels = df_train[\"relation\"].tolist()\n",
    "    test_labels = df_test[\"relation\"].tolist()\n",
    "else:\n",
    "    train_labels = [label2id.get(label, 0) for label in df_train[\"relation\"]]\n",
    "    test_labels = [label2id.get(label, 0) for label in df_test[\"relation\"]]\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = REDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = REDataset(test_texts, test_labels, tokenizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T14:05:38.552573200Z",
     "start_time": "2025-02-22T14:05:38.368148300Z"
    }
   },
   "id": "722e032d172bb64f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 加载BERT进行训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eb1b29f141330ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 使用BERT进行关系分类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87c92df7dfe800a8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95f985e98e9949ba8e46ed335a48f089"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=len(label_list)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-22T14:09:42.606971100Z",
     "start_time": "2025-02-22T14:08:54.019312Z"
    }
   },
   "id": "81ec448357ddc27e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练参数设置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3b52b35e72250d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-22T14:14:14.002503400Z"
    }
   },
   "id": "b2b7149f6d7312b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练和评估"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d9ab9c0c8276317"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (1) 训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "615a199c62b7d79d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd91c81c8633c069"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (2) 在测试集上评估"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57b7adb0441f59bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79ca6f4a44f36939"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 运行推理（Inference）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d045c8da27058f58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 对新句子进行预测"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04ff5be0162ebe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_relation(sentence):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(preprocess_text(sentence), return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    pred_label = torch.argmax(logits, dim=-1).item()\n",
    "    return id2label[pred_label]\n",
    "\n",
    "test_sentence = \"The <e1>storm</e1> caused severe <e2>flooding</e2> in the city.\"\n",
    "predicted_relation = predict_relation(test_sentence)\n",
    "print(\"Predicted Relation:\", predicted_relation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d30ed62cb0a9bd91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 保存和加载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a1983ee5e141184"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (1) 保存模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a84a3e51f65619ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert-relation-extraction\")\n",
    "tokenizer.save_pretrained(\"./bert-relation-extraction\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3accc7739fb8722"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (2) 加载模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18814047a9e8cf03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"./bert-relation-extraction\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./bert-relation-extraction\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e64a399dd10baddf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
